{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Using Naive Bayes classifier described in this chapter, and any features you can think of, build the best name gender classifier you can. Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the dev-test set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names \n",
    "import random\n",
    "\n",
    "\n",
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "   [(name, 'female') for name in names.words('female.txt')])\n",
    "\n",
    "random.seed(1) \n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(word):\n",
    "     return {'First_letter': word[0].lower()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = labeled_names[1000:]\n",
    "devtest_names = labeled_names[500:1000]\n",
    "test_names = labeled_names[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [(get_features(n), gender) for (n, gender) in train_names]\n",
    "devtest_set = [(get_features(n), gender) for (n, gender) in devtest_names]\n",
    "test_set = [(get_features(n), gender) for (n, gender) in test_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.634\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set) \n",
    "print(nltk.classify.accuracy(classifier, devtest_set)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features2(word):\n",
    "    features = {}\n",
    "    features['First_letter'] = word[0].lower()\n",
    "    features['Suffix'] = word[-2:].lower()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set2 = [(get_features2(n), gender) for (n, gender) in train_names]\n",
    "devtest_set2 = [(get_features2(n), gender) for (n, gender) in devtest_names]\n",
    "test_set2 = [(get_features2(n), gender) for (n, gender) in test_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.808\n"
     ]
    }
   ],
   "source": [
    "classifier2 = nltk.NaiveBayesClassifier.train(train_set2) \n",
    "print(nltk.classify.accuracy(classifier2, devtest_set2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features3(word):\n",
    "    features = {}\n",
    "    features['First_letter'] = word[0].lower()\n",
    "    features['Suffix'] = word[-2:].lower()\n",
    "    features['Name_length'] = len(word)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set3 = [(get_features3(n), gender) for (n, gender) in train_names]\n",
    "devtest_set3 = [(get_features3(n), gender) for (n, gender) in devtest_names]\n",
    "test_set3 = [(get_features3(n), gender) for (n, gender) in test_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.808\n"
     ]
    }
   ],
   "source": [
    "classifier3 = nltk.NaiveBayesClassifier.train(train_set3) \n",
    "print(nltk.classify.accuracy(classifier3, devtest_set3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I ran three get_features extractors based on what i thought were the best features to determine gender names.\n",
    "## When I had the first letter and last two letter suffixes, I got the highest accuracy metric.\n",
    "\n",
    "## Only using the first letter of a name gave me an accuracy metric of .634. And when I added name_length with first letter and\n",
    "## suffix, my accuracy metric did not improve. \n",
    "\n",
    "## I decided to go with get_features2. Now I will check its final performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier2, test_set2))\n",
    "## Using get_features2 gave me an accuracy measure of .81 on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Using the movie review document classifier discussed in Chapter 6- Section 1.3 ( constructing a list of the 2500 most frequent words as features and use the first 150 documents as the test dataset) , generate a list of the 10 features that the classifier finds to be most informative. Can you explain why these particular features are informative? Do you find any of them surprising?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "documents = [(list(movie_reviews.words(fileid)), category) ## a list of words from each review which is our input, not X, did not generate x yet\n",
    "            for category in movie_reviews.categories() ## positive or negative (label Y)\n",
    "            for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "random.seed(1)\n",
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = list(all_words)[:2000]\n",
    "\n",
    "def document_features(document): \n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8266666666666667\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[150:], featuresets[:150]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =     10.6 : 1.0\n",
      "         contains(mulan) = True              pos : neg    =      9.0 : 1.0\n",
      "        contains(seagal) = True              neg : pos    =      8.2 : 1.0\n",
      "   contains(wonderfully) = True              pos : neg    =      7.9 : 1.0\n",
      "         contains(awful) = True              neg : pos    =      5.7 : 1.0\n",
      "         contains(damon) = True              pos : neg    =      5.7 : 1.0\n",
      "         contains(flynt) = True              pos : neg    =      5.7 : 1.0\n",
      "          contains(lame) = True              neg : pos    =      5.6 : 1.0\n",
      "        contains(wasted) = True              neg : pos    =      5.1 : 1.0\n",
      "    contains(ridiculous) = True              neg : pos    =      5.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## These 10 features are important because they contain words that by definition can tell you if something is good or bad.\n",
    "## When we look at words with outstanding, wondefully, awful, lame, wasted, and ridiculous, we can identify how people felt \n",
    "## about those movies. On the other hand, words like mulan, seagal, damon, and flynt were surprising to see. \n",
    "\n",
    "## I have an explanation for those words as the following: \n",
    "## Mulan - In 1998, Disney released the movie Mulan, which many people liked and was viewed positively based on reviews.\n",
    "## seagal - Refers to the actor steven seagal, who's majority of movies were viewed as bad/negatively. \n",
    "## damon - Refers to the actor Matt Damon, who many see as an exceptional actor, and probably love the movies he stars in.\n",
    "## flynt - Refers to the movie, The People vs Larry Flynt, which has many positive reviews and is seen as a great movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Select one of the classification tasks described in this chapter, such as name gender detection, document classification, part-of-speech tagging, or dialog act classification. Using the same training and test data, and the same feature extractor, build three classifiers for the task: a decision tree, a naive Bayes classifier, and a  Maximum Entropy classifier. Compare the performance of the three classifiers on your selected task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "posts = nltk.corpus.nps_chat.xml_posts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dialogue_act_features(post):\n",
    "    features = {}\n",
    "    for word in nltk.word_tokenize(post):\n",
    "        features['contains({})'.format(word.lower())] = True\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(dialogue_act_features(post.text), post.get('class'))\n",
    "              for post in posts]\n",
    "\n",
    "size = int(len(featuresets) * 0.1)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NavieBayes:  0.6685606060606061\n"
     ]
    }
   ],
   "source": [
    "print(\"NavieBayes: \", nltk.classify.accuracy(NB_classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-72408dc35e01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mDT_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;31m# Refine the stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m         tree.refine(\n\u001b[0m\u001b[0;32m    175\u001b[0m             \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m             \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mrefine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mlabel_freqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLEProbDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_freqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 self._decisions[fval] = DecisionTreeClassifier.train(\n\u001b[0m\u001b[0;32m    233\u001b[0m                     \u001b[0mfval_featuresets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mentropy_cutoff\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;31m# Start with a stump.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m             tree = DecisionTreeClassifier.best_stump(\n\u001b[0m\u001b[0;32m    166\u001b[0m                 \u001b[0mfeature_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             )\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36mbest_stump\u001b[1;34m(feature_names, labeled_featuresets, verbose)\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[0mstump\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m             \u001b[0mstump_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstump\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstump_error\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbest_error\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m                 \u001b[0mbest_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstump_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Intel\\Python\\lib\\site-packages\\nltk\\classify\\decisiontree.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, labeled_featuresets)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mfeatureset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabeled_featuresets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatureset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DT_classifier = nltk.DecisionTreeClassifier.train(train_set) ## TAKES TOO LONG TOO RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DecisionTree: \", nltk.classify.accuracy(DT_classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (100 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -2.70805        0.051\n",
      "             2          -1.24967        0.848\n",
      "             3          -0.91881        0.884\n",
      "             4          -0.74746        0.900\n",
      "             5          -0.63429        0.911\n",
      "             6          -0.55128        0.921\n",
      "             7          -0.48745        0.924\n",
      "             8          -0.43747        0.928\n",
      "             9          -0.39805        0.932\n",
      "            10          -0.36667        0.936\n",
      "            11          -0.34127        0.940\n",
      "            12          -0.32028        0.943\n",
      "            13          -0.30259        0.945\n",
      "            14          -0.28740        0.947\n",
      "            15          -0.27419        0.949\n",
      "            16          -0.26256        0.951\n",
      "            17          -0.25220        0.953\n",
      "            18          -0.24292        0.954\n",
      "            19          -0.23453        0.956\n",
      "            20          -0.22690        0.957\n",
      "            21          -0.21993        0.958\n",
      "            22          -0.21352        0.959\n",
      "            23          -0.20761        0.959\n",
      "            24          -0.20213        0.960\n",
      "            25          -0.19704        0.961\n",
      "            26          -0.19229        0.961\n",
      "            27          -0.18784        0.962\n",
      "            28          -0.18367        0.962\n",
      "            29          -0.17975        0.963\n",
      "            30          -0.17605        0.963\n",
      "            31          -0.17256        0.964\n",
      "            32          -0.16926        0.965\n",
      "            33          -0.16612        0.965\n",
      "            34          -0.16314        0.966\n",
      "            35          -0.16031        0.966\n",
      "            36          -0.15761        0.967\n",
      "            37          -0.15503        0.967\n",
      "            38          -0.15257        0.968\n",
      "            39          -0.15022        0.968\n",
      "            40          -0.14796        0.968\n",
      "            41          -0.14580        0.969\n",
      "            42          -0.14372        0.969\n",
      "            43          -0.14172        0.969\n",
      "            44          -0.13980        0.969\n",
      "            45          -0.13795        0.970\n",
      "            46          -0.13617        0.970\n",
      "            47          -0.13445        0.970\n",
      "            48          -0.13279        0.971\n",
      "            49          -0.13119        0.971\n",
      "            50          -0.12964        0.972\n",
      "            51          -0.12815        0.972\n",
      "            52          -0.12670        0.972\n",
      "            53          -0.12529        0.972\n",
      "            54          -0.12393        0.973\n",
      "            55          -0.12261        0.973\n",
      "            56          -0.12133        0.973\n",
      "            57          -0.12009        0.973\n",
      "            58          -0.11888        0.974\n",
      "            59          -0.11771        0.974\n",
      "            60          -0.11657        0.974\n",
      "            61          -0.11546        0.975\n",
      "            62          -0.11438        0.975\n",
      "            63          -0.11333        0.975\n",
      "            64          -0.11230        0.975\n",
      "            65          -0.11131        0.976\n",
      "            66          -0.11033        0.976\n",
      "            67          -0.10938        0.976\n",
      "            68          -0.10846        0.976\n",
      "            69          -0.10755        0.976\n",
      "            70          -0.10667        0.976\n",
      "            71          -0.10581        0.976\n",
      "            72          -0.10497        0.977\n",
      "            73          -0.10414        0.977\n",
      "            74          -0.10334        0.977\n",
      "            75          -0.10255        0.977\n",
      "            76          -0.10178        0.977\n",
      "            77          -0.10103        0.977\n",
      "            78          -0.10029        0.978\n",
      "            79          -0.09957        0.978\n",
      "            80          -0.09886        0.978\n",
      "            81          -0.09817        0.978\n",
      "            82          -0.09749        0.978\n",
      "            83          -0.09683        0.978\n",
      "            84          -0.09618        0.978\n",
      "            85          -0.09554        0.978\n",
      "            86          -0.09491        0.978\n",
      "            87          -0.09429        0.978\n",
      "            88          -0.09369        0.978\n",
      "            89          -0.09310        0.978\n",
      "            90          -0.09252        0.978\n",
      "            91          -0.09194        0.979\n",
      "            92          -0.09138        0.979\n",
      "            93          -0.09083        0.979\n",
      "            94          -0.09029        0.979\n",
      "            95          -0.08976        0.979\n",
      "            96          -0.08924        0.979\n",
      "            97          -0.08872        0.979\n",
      "            98          -0.08822        0.979\n",
      "            99          -0.08772        0.979\n",
      "         Final          -0.08723        0.979\n"
     ]
    }
   ],
   "source": [
    "ME_classifier = nltk.MaxentClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaximumEntropy_classifier:  0.71875\n"
     ]
    }
   ],
   "source": [
    "print(\"MaximumEntropy_classifier: \", nltk.classify.accuracy(ME_classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## When running the different classifiers, NavieBayes, DecisionTree, and MaximumEntropy, we see that there is a difference on\n",
    "## how each output is processed.\n",
    "\n",
    "## First, NavieBayes, produces the lowest accuracy metric but its processing speed is the fastest.\n",
    "## Secondly, MaximumEntropy has the higher accuracy metric but it does produce an output slower than NavieBayes.\n",
    "## This happens because by default, MaximumEntropy does 100 iterations to find the set of parameters that will maximize the performance of the classifier.\n",
    "## Its accuracy metric is higher than NavieBayes at .71875.\n",
    "## Lastly, my DecisionTree classifier took forever to run but it will not produce an output.\n",
    "## This may be because my computer is ill-equipped to handle it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Identify the NPS Chat Corpus, which was demonstrated in Chapter 2, consists of posts from instant messaging sessions. These posts have all been labeled with one of 15 dialogue act types, such as \"Statement,\" \"Emotion,\" \"ynQuestion\", and \"Continuer.\" We can therefore use this data to build a classifier that can identify the dialogue act types for new instant messaging posts. Build a simple feature extractor that checks what words the post contains. Construct the training and testing data by applying the feature extractor to each post and create a Nave Bayes classifier. Please print the accuracy of this classifier. Please use NPS Chat Corpus as our dataset and use 8% data as our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = nltk.corpus.nps_chat.xml_posts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dialogue_act_features(post):\n",
    "    features = {}\n",
    "    for word in nltk.word_tokenize(post):\n",
    "        features['contains({})'.format(word.lower())] = True\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(dialogue_act_features(post.text), post.get('class'))\n",
    "              for post in posts]\n",
    "\n",
    "size = int(len(featuresets) * 0.08)\n",
    "train_set, test_set = featuresets[size:], featuresets[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.676923076923077\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5.Given the following confusion matrix, please calculate: a) Accuracy Rate; b) Precision; c) Recall; d) F-Measure.\n",
    "                 True\n",
    "\t            No\tYes\n",
    "Predicted No\t104\t 33\n",
    "          Yes\t13\t 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## accuracy rate = (True Positive + True Negative)/Number of Observations\n",
    "## Precision = True Positive / (True Positive + False Positive)\n",
    "## Recall = True Positive / (True Positive + False Negative)\n",
    "## F-Measure = 2 * (Precision * Recall)/ (Precision + Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Rate is 0.77\n"
     ]
    }
   ],
   "source": [
    "## 5a.\n",
    "AR = (50 + 104) / (104+33+13+50)\n",
    "print(\"Accuracy Rate is\", round(AR,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is 0.794\n"
     ]
    }
   ],
   "source": [
    "## 5b.\n",
    "PR = 50 / (50 + 13)\n",
    "print(\"Precision is\", round(PR,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall is 0.602\n"
     ]
    }
   ],
   "source": [
    "## 5c.\n",
    "RC = 50 / (50 + 33)\n",
    "print(\"Recall is\", round(RC,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure is 0.685\n"
     ]
    }
   ],
   "source": [
    "## 5d.\n",
    "F1M = 2* (PR*RC) / (PR + RC) \n",
    "print(\"F-Measure is\", round(F1M,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Write a tag pattern to match noun phrases containing plural head nouns in the following sentence: \"Many researchers discussed this project for two weeks.\" Try to do this by generalizing the tag pattern that handled singular noun phrases too. Please 1) pos-tag this sentence 2) write a tag pattern (i.e. grammar); 3) use RegexpParser to parse the sentence and 4) print out the result containing NP (noun phrases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_sample = \"Many researchers discussed this project for two weeks.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(doc_sample) \n",
    "tokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "tagged_sentences = [nltk.pos_tag(sent) for sent in tokenized_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Many', 'JJ'),\n",
       "  ('researchers', 'NNS'),\n",
       "  ('discussed', 'VBD'),\n",
       "  ('this', 'DT'),\n",
       "  ('project', 'NN'),\n",
       "  ('for', 'IN'),\n",
       "  ('two', 'CD'),\n",
       "  ('weeks', 'NNS'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "    NP: {<NN.*>+} \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('S', [('Many', 'JJ'), Tree('NP', [('researchers', 'NNS')]), ('discussed', 'VBD'), ('this', 'DT'), Tree('NP', [('project', 'NN')]), ('for', 'IN'), ('two', 'CD'), Tree('NP', [('weeks', 'NNS')]), ('.', '.')])]\n"
     ]
    }
   ],
   "source": [
    "### print(cp.parse(tagged_sentence)) was not working and im not sure why that is.\n",
    "### So i had to print the pos separately using an empty list and going through each word within the tagged_sentences.\n",
    "chunked = []\n",
    "for sent in tagged_sentences:\n",
    "    chunked.append(cp.parse(sent))\n",
    "print(chunked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Write a tag pattern to cover noun phrases that contain gerunds, e.g. \"the/DT receiving/VBG end/NN\", \"assistant/NN                      managing/VBG editor/NN\". Add these patterns to the grammar, one per line. Test your work using some tagged sentences of your own  devising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [(\"the\", \"DT\"), (\"receiving\",\"VBG\"), (\"end\",\"NN\"), (\"assistant\", \"NN\"), (\"managing\", \"VBG\"), (\"editor\", \"NN\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "    NP: {<DT>}   \n",
    "        {<VBG>}\n",
    "        {<NN.*>} \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP the/DT)\n",
      "  (NP receiving/VBG)\n",
      "  (NP end/NN)\n",
      "  (NP assistant/NN)\n",
      "  (NP managing/VBG)\n",
      "  (NP editor/NN))\n"
     ]
    }
   ],
   "source": [
    "cp = nltk.RegexpParser(grammar)\n",
    "print(cp.parse(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Use the Brown Corpus and the cascaded chunkers that has patterns for noun phrases, prepositional phrases, verb phrases, and clauses to print out all the verb phrases in the Brown corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = r\"\"\"\n",
    "    NP: {<DT|JJ|NN.*>+}\n",
    "    PP: {<IN><NP>}     \n",
    "    VP: {<VB.*><NP|PP|CLAUSE>+$}\n",
    "    CLAUSE: {<NP><VP>}\n",
    "    \"\"\"\n",
    "cp = nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(VP Ask/VB-HL (NP jail/NN-HL deputies/NNS-HL))\n",
      "(VP revolving/VBG-HL (NP fund/NN-HL))\n",
      "(VP Issue/VB-HL (NP jury/NN-HL subpoenas/NNS-HL))\n",
      "(VP Nursing/VBG-HL (NP home/NN-HL care/NN-HL))\n",
      "(VP pay/VB-HL (NP doctors/NNS-HL))\n",
      "(VP nursing/VBG-HL (NP homes/NNS))\n",
      "(VP Asks/VBZ-HL (NP research/NN-HL funds/NNS-HL))\n",
      "(VP Regrets/VBZ-HL (NP attack/NN-HL))\n",
      "(VP Decries/VBZ-HL (NP joblessness/NN-HL))\n",
      "(VP Underlying/VBG-HL (NP concern/NN-HL))\n",
      "(VP bar/VB-HL (NP vehicles/NNS-HL))\n",
      "(VP loses/VBZ-HL (NP pace/NN-HL))\n",
      "(VP hits/VBZ-HL (NP homer/NN-HL))\n",
      "(VP attend/VB-HL (NP races/NNS-HL))\n",
      "(VP follows/VBZ-HL (NP ceremonies/NNS-HL))\n",
      "(VP Noted/VBN-HL (NP artist/NN-HL))\n",
      "(VP Cites/VBZ-HL (NP discrepancies/NNS-HL))\n",
      "(VP calls/VBZ-HL (NP police/NNS-HL))\n",
      "(VP held/VBN-HL (NP key/NN-HL))\n",
      "(VP grant/VB-HL (NP bail/NN-HL))\n",
      "(VP Held/VBD-HL (NP candle/NN-HL))\n",
      "(VP Expresses/VBZ-HL (NP thanks/NNS-HL))\n",
      "(VP Gets/VBZ-HL (NP car/NN-HL number/NN-HL))\n",
      "(VP Attacks/VBZ-HL (NP officer/NN-HL))\n",
      "(VP oks/VBZ-HL (NP pact/NN-HL))\n",
      "(VP report/VB-HL (NP gains/NNS-HL))\n",
      "(VP Pulling/VBG-HL (NP strings/NNS-HL))\n",
      "(VP United/VBN-TL-HL (NP States/NNS-TL-HL defense/NN-HL))\n",
      "(VP Betting/VBG-HL (NP men/NNS-HL))\n",
      "(VP brings/VBZ-HL (NP numbness/NN-HL))\n",
      "(VP Questions/VBZ-HL (NP shelters/NNS-HL))\n",
      "(VP Marketing/VBG-HL (NP meat/NN-HL))\n",
      "(VP Taxing/VBG-HL (NP improvements/NNS-HL))\n",
      "(VP Praises/VBZ-HL (NP exhibit/NN-HL))\n",
      "(VP aid/VB (NP international/JJ law/NN))\n",
      "(VP retarded/VBN-HL (NP children/NNS-HL))\n",
      "(VP tormented/VBN-HL (NP span/NN-HL))\n",
      "(VP dashed/VBN-HL (NP hope/NN-HL))\n",
      "(VP open/VB-HL (NP program/NN-HL))\n",
      "(VP Fleeting/VBG-HL (NP glimpse/NN-HL))\n",
      "(VP fragmented/VBN-HL (NP Society/NN-TL-HL))\n",
      "(VP locking/VBG-HL (NP bars/NNS-HL))\n",
      "(VP fire/VB (NP standard/JJ))\n",
      "(VP Canned/VBN-HL (NP cocktail/NN-HL frankfurters/NNS-HL))\n",
      "(VP whipped/VBN (NP Salt/NN Paprika/NN))\n",
      "(VP Barbecued/VBN-HL (NP frankfurters/NNS-HL))\n",
      "(VP Changing/VBG-HL (NP colors/NNS-HL))\n",
      "(VP Measuring/VBG-HL (NP armhole/NN-HL))\n",
      "(VP Backstitching/VBG-HL (NP seam/NN-HL))\n",
      "(VP Weaving/VBG-HL (NP seam/NN-HL))\n",
      "(VP drilling/VBG-HL (NP tools/NNS-HL))\n",
      "(VP drilling/VBG-HL (NP operations/NNS-HL))\n",
      "(VP Adjoining/VBG-HL (NP areas/NNS-HL))\n",
      "(VP chinning/VBG-HL (NP bar/NN-HL))\n",
      "(VP fattening/VBG-HL (NP rations/NNS-HL))\n",
      "(VP marketing/VBG-HL (NP methods/NNS-HL))\n",
      "(VP marketing/VBG-HL (NP management/NN-HL))\n",
      "(VP feeding/VBG-HL (NP facilities/NNS-HL))\n",
      "(VP Paid/VBN-HL (NP vacations/NNS-HL))\n",
      "(VP Eating/VBG-HL (NP facilities/NNS-HL))\n",
      "(VP farming/VBG-HL (NP methods/NNS-HL))\n",
      "(VP Nourishing/VBG (NP meals/NNS))\n",
      "(VP save/VB-HL (NP teeth/NNS-HL))\n",
      "(VP helps/VBZ-HL (NP families/NNS-HL))\n",
      "(VP Printed/VBN-HL (NP material/NN-HL))\n",
      "(VP Printed/VBN-HL (NP material/NN-HL))\n",
      "(VP Printed/VBN-HL (NP material/NN-HL))\n",
      "(VP Printed/VBN-HL (NP material/NN-HL))\n",
      "(VP planning/VBG-HL (NP process/NN-HL))\n",
      "(VP applying/VBG-HL (NP conditions/NNS-HL))\n",
      "(VP Encouraging/VBG-HL (NP self-help/NN-HL))\n",
      "(VP stressing/VBG-HL (NP self-help/NN-HL))\n",
      "(VP nearing/VBG-HL (NP self-sufficiency/NN-HL))\n",
      "(VP Advertising/VBG-HL (NP program/NN-HL))\n",
      "(VP Planning/VBG-HL (NP division/NN-HL))\n",
      "(VP financing/VBG-HL (NP adjustments/NNS-HL))\n",
      "(VP distributing/VBG-HL (NP funds/NNS-HL))\n",
      "(VP Matching/VBG-HL (NP requirements/NNS-HL))\n",
      "(VP prepared/VBN (NP shelter/NN))\n",
      "(VP Increased/VBN-HL (NP efficiency/NN-HL))\n",
      "(VP shifting/VBG-HL (NP styles/NNS-HL))\n",
      "(VP broadcasting/VBG-HL (NP station/NN-HL))\n",
      "(VP cleaning/VBG-HL (NP process/NN-HL))\n",
      "(VP frozen/VBN-HL (NP sections/NNS-HL))\n",
      "(VP Staining/VBG-HL (NP technique/NN-HL))\n",
      "(VP Concluding/VBG-HL (NP remarks/NNS-HL))\n",
      "(VP modernizing/VBG-HL (NP societies/NNS-HL))\n",
      "(VP teaching/VBG-HL (NP methods/NNS-HL))\n",
      "(VP teaching/VBG-HL (NP methods/NNS-HL))\n",
      "(VP bargaining/VBG-HL (NP issues/NNS-HL))\n",
      "(VP\n",
      "  selecting/VBG-HL\n",
      "  (NP mail/NN-HL questionnaire/NN-HL method/NN-HL))\n",
      "(VP mailing/VBG-HL (NP lists/NNS-HL))\n",
      "(VP distributed/VBN-HL (NP cost/NN-HL analysis/NN-HL))\n",
      "(VP define/VB-HL (NP input/output/NN-HL control/NN-HL system/NN-HL))\n",
      "(VP related/VBN-HL (NP materials/NNS-HL))\n",
      "(VP ionizing/VBG-HL (NP radiation/NN-HL))\n",
      "(VP seen/VBN (NP that/DT Af/NN))\n",
      "(VP\n",
      "  Chipping/VBG\n",
      "  (NP mechanism/NN)\n",
      "  (PP of/IN (NP cohesive/JJ failure/NN)))\n",
      "(VP cracking/VBG-HL (NP mechanism/NN-HL))\n",
      "(VP Processing/VBG-HL (NP urethanes/NNS-HL))\n",
      "(VP coupled/VBN-HL (NP image/NN-HL intensifiers/NNS-HL))\n",
      "(VP following/VBG (NP morning/NN))\n",
      "(VP whining/VBG (NP voice/NN))\n",
      "(VP convinced/VBN (PP of/IN (NP that/DT)))\n"
     ]
    }
   ],
   "source": [
    "for sent in nltk.corpus.brown.tagged_sents():\n",
    "    tree = cp.parse(sent)\n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.label() == \"VP\": print(subtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. The bigram chunker scores about 90% accuracy. Using bigram_chunker.tagger.tag(postags) to examine the results and study its errors. Then experiment with trigram chunking. Are you able to improve the performance any more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import conll2000\n",
    "\n",
    "test_sents = conll2000.chunked_sents('test.txt', chunk_types=['NP'])\n",
    "train_sents = conll2000.chunked_sents('train.txt', chunk_types=['NP'])\n",
    "\n",
    "class BigramChunker(nltk.ChunkParserI):\n",
    "    def __init__(self, train_sents): \n",
    "        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)]\n",
    "                      for sent in train_sents]\n",
    "        self.tagger = nltk.BigramTagger(train_data)\n",
    "    def parse(self, sentence): \n",
    "        pos_tags = [pos for (word,pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag)\n",
    "                     in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)\n",
    "    \n",
    "postags = sorted(set(pos for sent in train_sents\n",
    "                    for (word,pos) in sent.leaves()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  93.3%%\n",
      "    Precision:     82.3%%\n",
      "    Recall:        86.8%%\n",
      "    F-Measure:     84.5%%\n"
     ]
    }
   ],
   "source": [
    "bigram_chunker = BigramChunker(train_sents)\n",
    "print(bigram_chunker.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('#', 'B-NP'), ('$', 'I-NP'), (\"''\", 'O'), ('(', 'O'), (')', 'O'), (',', 'O'), ('.', 'O'), (':', 'O'), ('CC', 'O'), ('CD', 'B-NP'), ('DT', 'I-NP'), ('EX', 'B-NP'), ('FW', 'I-NP'), ('IN', 'O'), ('JJ', 'B-NP'), ('JJR', 'I-NP'), ('JJS', 'I-NP'), ('MD', 'O'), ('NN', 'B-NP'), ('NNP', 'I-NP'), ('NNPS', 'I-NP'), ('NNS', 'I-NP'), ('PDT', 'I-NP'), ('POS', 'B-NP'), ('PRP', 'B-NP'), ('PRP$', 'I-NP'), ('RB', 'O'), ('RBR', 'O'), ('RBS', 'B-NP'), ('RP', None), ('SYM', None), ('TO', None), ('UH', None), ('VB', None), ('VBD', None), ('VBG', None), ('VBN', None), ('VBP', None), ('VBZ', None), ('WDT', None), ('WP', None), ('WP$', None), ('WRB', None), ('``', None)]\n"
     ]
    }
   ],
   "source": [
    "print(bigram_chunker.tagger.tag(postags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  93.3%%\n",
      "    Precision:     82.5%%\n",
      "    Recall:        86.8%%\n",
      "    F-Measure:     84.6%%\n"
     ]
    }
   ],
   "source": [
    "class TrigramChunker(nltk.ChunkParserI):\n",
    "    def __init__(self, train_sents): \n",
    "        train_data = [[(t,c) for w,t,c in nltk.chunk.tree2conlltags(sent)]\n",
    "                      for sent in train_sents]\n",
    "        self.tagger = nltk.TrigramTagger(train_data)\n",
    "    def parse(self, sentence): \n",
    "        pos_tags = [pos for (word,pos) in sentence]\n",
    "        tagged_pos_tags = self.tagger.tag(pos_tags)\n",
    "        chunktags = [chunktag for (pos, chunktag) in tagged_pos_tags]\n",
    "        conlltags = [(word, pos, chunktag) for ((word,pos),chunktag)\n",
    "                     in zip(sentence, chunktags)]\n",
    "        return nltk.chunk.conlltags2tree(conlltags)\n",
    "    \n",
    "trigram_chunker = TrigramChunker(train_sents)\n",
    "print(trigram_chunker.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('#', 'B-NP'), ('$', 'I-NP'), (\"''\", 'O'), ('(', 'O'), (')', 'O'), (',', 'O'), ('.', 'O'), (':', 'O'), ('CC', 'O'), ('CD', 'B-NP'), ('DT', 'I-NP'), ('EX', 'B-NP'), ('FW', 'I-NP'), ('IN', 'O'), ('JJ', 'B-NP'), ('JJR', 'I-NP'), ('JJS', 'I-NP'), ('MD', 'O'), ('NN', 'B-NP'), ('NNP', 'I-NP'), ('NNPS', 'I-NP'), ('NNS', 'I-NP'), ('PDT', None), ('POS', None), ('PRP', None), ('PRP$', None), ('RB', None), ('RBR', None), ('RBS', None), ('RP', None), ('SYM', None), ('TO', None), ('UH', None), ('VB', None), ('VBD', None), ('VBG', None), ('VBN', None), ('VBP', None), ('VBZ', None), ('WDT', None), ('WP', None), ('WP$', None), ('WRB', None), ('``', None)]\n"
     ]
    }
   ],
   "source": [
    "print(trigram_chunker.tagger.tag(postags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## It has discovered that most punctuation marks occur outside of NP chunks, with the exception of # and $, \n",
    "## both of which are used as currency markers. \n",
    "## It has also found that determiners (DT) and possessives (PRP$ and WP$) occur at the beginnings of NP chunks, \n",
    "## while noun types (NN, NNP, NNPS, NNS) mostly occur inside of NP chunks.\n",
    "\n",
    "## We could not improve the current measurement metrics using an Trigram_Chunker, although there are small changes to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Explore the Brown Corpus to print out all the FACILITIES (one of the commonly used types of name entities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = nltk.corpus.brown.tagged_sents()[75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  A/AT\n",
      "  veteran/JJ\n",
      "  Jackson/NP-TL\n",
      "  County/NN-TL\n",
      "  legislator/NN\n",
      "  will/MD\n",
      "  ask/VB\n",
      "  the/AT\n",
      "  (ORGANIZATION Georgia/NP-TL)\n",
      "  (ORGANIZATION House/NN-TL)\n",
      "  Monday/NR\n",
      "  to/TO\n",
      "  back/VB\n",
      "  federal/JJ\n",
      "  aid/NN\n",
      "  to/IN\n",
      "  education/NN\n",
      "  ,/,\n",
      "  something/PN\n",
      "  it/PPS\n",
      "  has/HVZ\n",
      "  consistently/RB\n",
      "  opposed/VBN\n",
      "  in/IN\n",
      "  the/AT\n",
      "  past/NN\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "print(nltk.ne_chunk(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(FACILITY Raymondville/NP)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY Kremlin/NP)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY Franklin/NP-TL)\n",
      "(FACILITY Kremlin/NP)\n",
      "(FACILITY Franklin/NP-TL Square/NN-TL)\n",
      "(FACILITY Pennsylvania/NP-TL Avenue/NN-TL)\n",
      "(FACILITY Jenks/NP-TL Street/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY Pensacola/NP)\n",
      "(FACILITY White/JJ-TL Sox/NPS-TL)\n",
      "(FACILITY Caltech/NP)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY Caracas/NP)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL Way/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY Kremlin/NP)\n",
      "(FACILITY Kremlin/NP)\n",
      "(FACILITY Madison/NP-TL Square/NN-TL Garden/NN-TL)\n",
      "(FACILITY Boron/NP)\n",
      "(FACILITY Rome/NP)\n",
      "(FACILITY Rome/NP)\n",
      "(FACILITY Grafton/NP)\n",
      "(FACILITY Bari/NP)\n",
      "(FACILITY Bari/NP)\n",
      "(FACILITY Northfield/NP)\n",
      "(FACILITY Baltimore/NP)\n",
      "(FACILITY Hilo/NP)\n",
      "(FACILITY Hilo/NP)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY Kremlin/NP)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/JJ-TL House/NN-TL)\n",
      "(FACILITY Whitemarsh/NP)\n",
      "(FACILITY Whitemarsh/NP)\n",
      "(FACILITY Versailles/NP)\n",
      "(FACILITY Marston/NP)\n",
      "(FACILITY Israelite/NP)\n",
      "(FACILITY Whiteleaf/NP)\n",
      "(FACILITY Ninth/OD-TL Street/NN-TL)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY White/NP)\n",
      "(FACILITY Teheran/NP)\n",
      "(FACILITY Teheran/NP)\n",
      "(FACILITY White/NP)\n",
      "(FACILITY Grafton/NP)\n",
      "(FACILITY Lublin/NP)\n",
      "(FACILITY Winston/NP)\n",
      "(FACILITY Clayton/NP)\n",
      "(FACILITY Penny/NP)\n",
      "(FACILITY Jack/NP)\n",
      "(FACILITY Francie/NP)\n",
      "(FACILITY Phil/NP)\n",
      "(FACILITY White/JJ-TL)\n",
      "(FACILITY Berlin/NP)\n"
     ]
    }
   ],
   "source": [
    "for sent in nltk.corpus.brown.tagged_sents()[:100000]:\n",
    "    tree = nltk.ne_chunk(sent)\n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.label() == \"FACILITY\": print(subtree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
